# -*- coding: utf-8 -*-
"""image_to_text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h1B2Gv0LyWrxkYsUjy9UaKzIG5d8b0v3
"""

import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image

# Функция для генерации описания изображения
def generate_image_caption(image_path):
    # Загрузим модель и процессор BLIP
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

    # Открываем изображение
    image = Image.open(image_path).convert('RGB')

    # Препроцессинг изображения
    inputs = processor(image, return_tensors="pt")

    # Генерация текстового описания
    out = model.generate(**inputs)

    # Декодирование ответа
    caption = processor.decode(out[0], skip_special_tokens=True)
    return caption

# Пример вызова функции
image_path = "hqdefault.jpg"  # Укажите путь к изображению
caption = generate_image_caption(image_path)
print(f"Описание изображения: {caption}")